{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikUJITDDIp19",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Intro to Python Acceleration and CSV Analysis\n",
    "\n",
    "## Introduction\n",
    "This notebook serves as an introduction to Python for a mechanical engineer looking to plot and analyze some acceleration data in a CSV file. Being a Colab, this tool can freely be used without installing anything.\n",
    "\n",
    "For more information on making the swith to Python see [enDAQ's blog, Why and How to Get Started in Python for a MATLAB User](https://blog.endaq.com/why-and-how-to-get-started-in-python-for-a-matlab-user).\n",
    "\n",
    "This is part of our webinar series on Python for Mechanical Engineers:\n",
    "\n",
    "1. **Get Started with Python**\n",
    "   * [Watch Recording of This](https://info.endaq.com/why-mechanical-engineers-should-use-python-webinar)\n",
    "2. [Introduction to Numpy & Pandas for Data Analysis](https://colab.research.google.com/drive/1O-VwAdRoSlcrineAk0Jkd_fcw7mFGHa4#scrollTo=ce97q1ZcBiwj)\n",
    "3. [Introduction to Plotly for Plotting Data](https://colab.research.google.com/drive/1pag2pKQQW5amWgRykAH8uMAPqHA2yUfU)\n",
    "4. [Introduction of the enDAQ Library](https://colab.research.google.com/drive/1WAtQ8JJC_ny0fki7eUABACMA-isZzKB6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou9NjNsdJ72B",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Data File\n",
    "We will assume that the first column is time in seconds. Some example files are provided or you can load your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vX2hd0kHKPz4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example Files\n",
    "Here are some example datasets you can use to do some initial testing. If you have uploaded your own data, you'll want to comment this out or not run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ut2acKSEKN1C",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "filenames = ['https://info.endaq.com/hubfs/data/surgical-instrument.csv',\n",
    "             'https://info.endaq.com/hubfs/data/blushift.csv',\n",
    "             'https://info.endaq.com/hubfs/Plots/bearing_data.csv', #used in this dataset: https://blog.endaq.com/top-vibration-metrics-to-monitor-how-to-calculate-them\n",
    "             'https://info.endaq.com/hubfs/data/Motorcycle-Car-Crash.csv', #used in this blog: https://blog.endaq.com/shock-analysis-response-spectrum-srs-pseudo-velocity-severity\n",
    "             'https://info.endaq.com/hubfs/data/Calibration-Shake.csv',\n",
    "             'https://info.endaq.com/hubfs/data/Mining-Hammer.csv'] #largest dataset\n",
    "filename = filenames[4]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MaNRqOKcbNsl",
    "outputId": "1b96883c-ba3d-49c3-d3e8-745a1700de73",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "filenames[4]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyguF5C1Ju8l",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Install & Import Libraries\n",
    "\n",
    "First we'll install all libraries we'll need, then import them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQIa2uQNOR_K",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that if running this locally you'll only need to install one time, then subsequent runs can just do the import. But colab and anaconda will contain all the libraries we'll need anyways so the install isn't necessary. Here is how the install would be done though:\n",
    "\n",
    "```\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install plotly\n",
    "!pip install scipy\n",
    "```\n",
    "\n",
    "You can always check which libraries you have installed by doing:\n",
    "\n",
    "```\n",
    "!pip freeze\n",
    "```\n",
    "\n",
    "We do need to upgrade plotly though to work in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rKONh6lJYtF6",
    "outputId": "e0c78623-92a5-43e8-d0b7-22fddf826f09",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "!pip install --upgrade plotly"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9lHwj3pIozY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we'll import our libraries we'll use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4s3mCpAZNAZq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as xp\n",
    "import plotly.io as pio; pio.renderers.default = \"iframe\"\n",
    "from scipy import signal"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HshMSZdObSY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the CSV, Analyze & Plot\n",
    "We'll load the data into pandas, display it, do some very basic analysis, and plot the time history in a few ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFbCjAMxPx0G",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the CSV File and Prepare\n",
    "Remember we are expecting the first column to be time and will set it as the index. This is loading a CSV file, but Pandas supports a lot of other file formats, see: [Pandas Input/Output](https://pandas.pydata.org/docs/reference/io.html).\n",
    "\n",
    "If you must/need to use .MAT files, scipy can read these: [scipy.io.loadmat](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "sXOwidDEOrS0",
    "outputId": "21e88975-7eac-4088-8c7f-24599ba1012a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "df = pd.read_csv(filename) #load the data\n",
    "df = df.set_index(df.columns[0]) #set the first column as the index\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_tOgtT5P4Y5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Basic Analysis\n",
    "Once in a Pandas dataframe, doing some basic analysis is SUPER easy as shown. Here's a [link to the docs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.max.html) for the .max() function, but notice the many others readily available.\n",
    "\n",
    "The peak will be applied after first finding the absolute value to ensure we don't ignore large negative values. \n",
    "\n",
    "$$peak=\\max(\\left | a \\right |)$$\n",
    "\n",
    "Then the RMS is a simple square root of the mean of all the values squared. \n",
    "\n",
    "$$rms = \\sqrt{\\left(\\frac{1}{n}\\right)\\sum_{i=1}^{n}(a_{i})^{2}}$$\n",
    "\n",
    "The crest factor is equal to the peak divided by the RMS.\n",
    "$$crest = \\frac{peak}{rms}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "oxFZ6Oj0O2Pr",
    "outputId": "98837822-36b4-4ef3-c319-fe32e31956bc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "abs_max = df.abs().max() #maximum of the absolute values, the peak\n",
    "std = df.std() #standard deviation (equivalent to the AC coupled RMS value)\n",
    "crest_factor = abs_max/std #crest factor (peak / RMS)\n",
    "\n",
    "stats = pd.concat([abs_max, #combine the stats into one table\n",
    "                   std,\n",
    "                   crest_factor],\n",
    "                  axis=1)\n",
    "stats.columns = ['Peak Acceleration (g)','RMS (g)','Crest Factor'] #set the headers of the table\n",
    "stats"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJTBXREgRm-U",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot Full Time Series\n",
    "You can create a plot very simply once you have a dataframe by just doing:\n",
    "~~~\n",
    "df.plot()\n",
    "~~~\n",
    "Here we show how to manipulate this plot a bit with axes labels in Matplotlib which has a very similar interface to MATLAB. There are a lot of [pretty well documented examples on matplotlib's docs site](https://matplotlib.org/stable/gallery/index.html) (but their docs are confusing to navigate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "K1ZUY6PNP7ab",
    "outputId": "d6aaccfa-76ad-4f05-9346-50ff67638ee3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "fig, ax = plt.subplots() #create an empty plot\n",
    "\n",
    "df.plot(ax=ax) #use the dataframe to add plot data, tell it to add to the already created axes\n",
    "\n",
    "ax.set(xlabel='Time (s)',\n",
    "       ylabel='Acceleration (g)',\n",
    "       title=filename)\n",
    "ax.grid() #turn on gridlines\n",
    "\n",
    "fig.savefig('full-time-history.png')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xme7PeHrWzU8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot with Plotly\n",
    "Matplotlib may be familiar, but Plotly offers much more interactivity directly in a browser. They also have really [good documentation with a ton of examples online](https://plotly.com/python/).\n",
    "\n",
    "The trouble is that plotting too many data points may be sluggish. I've long maintained that plotting 10s of thousands of data points isn't very useful anyways, you just get a shaded mess. \n",
    "\n",
    "So here we'll plot:\n",
    "\n",
    "- The moving peak value\n",
    "- The moving RMS\n",
    "- The time history around the peak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qamxSVYbHLz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Moving Peak\n",
    "This takes advantage of Pandas [rolling() function](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "03td9T_yeIFn",
    "outputId": "9d282cb6-2681-4b6a-a12f-91262d836c1f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "n_steps = 100 #number of points to plot\n",
    "n = int(df.shape[0]/n_steps) #number of data points to use in windowing\n",
    "df_rolling_peak = df.abs().rolling(n).max().iloc[::n] #finds the absolute value of every datapoint, then does a rolling maximum of the defined window size, then subsamples every nth point\n",
    "\n",
    "df_rolling_peak"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "6uubzmj7X8-V",
    "outputId": "3050a9a0-88ab-4451-9de6-67d82648bbdd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "fig = xp.line(df_rolling_peak)\n",
    "fig.update_layout(\n",
    "    title=\"Rolling Peak\",\n",
    "    xaxis_title=\"Time (s)\",\n",
    "    yaxis_title=\"Acceleration (g)\",\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html('rolling_peak.html',full_html=False,include_plotlyjs='cdn')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdJZtyIpaImV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Moving RMS\n",
    "Now we'll plot the rolling RMS using the standard deviation. Notice that these rolling value plots make it much easier to compare the datasets than by trying to plot all values which result in a shaded mess.\n",
    "\n",
    "Also in this example I'm showing how easy it is to [change the theme of the plotly figure, see their documentation](https://plotly.com/python/templates/) for more examples and information. You can also make custom themes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "emiCK-7vYJP0",
    "outputId": "d9aa4fd8-b9ad-4eca-db73-93c962f4ce44",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "df_rolling_rms = df.rolling(n).std().iloc[::n] #does a rolling standard deviation of the defined window size, then subsamples every nth point\n",
    "\n",
    "fig = xp.line(df_rolling_rms)\n",
    "fig.update_layout(\n",
    "    title=\"Rolling RMS\",\n",
    "    xaxis_title=\"Time (s)\",\n",
    "    yaxis_title=\"Acceleration (g)\",\n",
    "    template=\"plotly_dark\"\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html('rolling_rms.html',full_html=False,include_plotlyjs='cdn')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naRQofdha_3M",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Time History Around Peak\n",
    "Now let's find the time that had the maximum value and display the time history around that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EiNO0_vDKKsy",
    "outputId": "21220e37-f7b0-4aa7-e0ec-12183c3390cf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "df.abs().max(axis=1).idxmax()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "vbsRy0N0aY1E",
    "outputId": "bfdafee7-7c6e-4ee5-cedf-a1fe096580c7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "peak_time = df.abs().max(axis=1).idxmax() #get the time at which the peak value occurs\n",
    "d_t = (df.index[-1]-df.index[0])/(len(df.index)-1) #find the average time step\n",
    "fs = 1/d_t #find the sampling rate\n",
    "\n",
    "num = 1000 / 2 #total number of datapoints to plot (divide by 2 because it will be two sided)\n",
    "df_peak = df[peak_time - num / fs : peak_time + num / fs ] #segment the dataframe to be around that peak value\n",
    "\n",
    "fig = xp.line(df_peak)\n",
    "fig.update_layout(\n",
    "    title=\"Time History around Peak\",\n",
    "    xaxis_title=\"Time (s)\",\n",
    "    yaxis_title=\"Acceleration (g)\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html('time_history_peak.html',full_html=False,include_plotlyjs='cdn')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7KTFZNijXgI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## PSD\n",
    "Now using SciPy we can easily compute and plot a PSD using a custom function we'll make to ease the interface to [SciPy's Welch function](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html). This is very similar to [MATLAB's version](https://www.mathworks.com/help/signal/ref/pwelch.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ihz-UEolbyNT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def get_psd(df, bin_width=1.0, window=\"hann\"):\n",
    "    d_t = (df.index[-1]-df.index[0])/(len(df.index)-1)\n",
    "    fs = 1/d_t\n",
    "    f, psd = signal.welch(\n",
    "        df.values, fs=fs, nperseg= int(fs / bin_width), window=window, axis=0\n",
    "    )\n",
    "\n",
    "    df_psd = pd.DataFrame(psd, columns=df.columns)\n",
    "    df_psd[\"Frequency (Hz)\"] = f\n",
    "    df_psd = df_psd.set_index(\"Frequency (Hz)\")\n",
    "    return df_psd\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "9iXUTdMfodir",
    "outputId": "b5e8f5d9-e5a0-4e18-bd01-5ae033d62d76",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "df_psd = get_psd(df,bin_width=4) #compute a PSD with a 1 Hz bin width\n",
    "df_psd.to_csv('psd.csv') #save to a CSV file\n",
    "df_psd"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "jE2ZLBW-aeZr",
    "outputId": "2ff24aca-75ef-4434-c45d-37e988e426ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "fig = xp.line(df_psd)\n",
    "fig.update_layout(\n",
    "    title=\"Power Spectral Density (PSD)\",\n",
    "    xaxis_title=\"Frequency (Hz)\",\n",
    "    yaxis_title=\"Acceleration (g^2/Hz)\",\n",
    "    xaxis_type=\"log\",\n",
    "    yaxis_type=\"log\"\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html('psd.html',full_html=False,include_plotlyjs='cdn')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xA_ZSrAM48Sp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cumulative RMS from PSD\n",
    "Now that we have the PSD, we can easily compute and plot the overall RMS value. This is partially thanks to the [cumulative sum function](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html) in Pandas. \n",
    "\n",
    "The nice thing about a PSD (in addition to the easy control of the bin width) is that the area directly relates to the RMS level in the time domain. The equation is as follows.\n",
    "\n",
    "$$ g_{\\text{RMS}}=\\sqrt{\\int \\text{PSD}(f)\\ df} $$\n",
    "\n",
    "Let's demonstrate by quickly using the PSD just calculated, integrating, and taking the square root and compare to the values we calculated from the time domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIikvleC5BIe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def rms_from_psd(df_psd):\n",
    "    d_f = df_psd.index[1] - df_psd.index[0]\n",
    "    df_rms = df_psd.copy()\n",
    "    df_rms = df_rms*d_f\n",
    "    df_rms = df_rms.cumsum()\n",
    "    return(df_rms**0.5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "5w283bcf5MVd",
    "outputId": "f4b6f52c-54fd-445f-d135-7bdf634e9360",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "df_rms = rms_from_psd(df_psd)\n",
    "\n",
    "fig = xp.line(df_rms)\n",
    "fig.update_layout(\n",
    "    title=\"Cumulative RMS\",\n",
    "    xaxis_title=\"Frequency (Hz)\",\n",
    "    yaxis_title=\"Acceleration (g RMS)\",\n",
    "    xaxis_type=\"log\",\n",
    "    #yaxis_type=\"log\"\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html('cum_rms.html',full_html=False,include_plotlyjs='cdn')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqZQytK3jLju",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## FFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQ6Asg0zjOWn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Typical FFT (Or Should We Say DFT)\n",
    "This uses SciPy's discrete [Fourier transform function](https://docs.scipy.org/doc/scipy/reference/generated/scipy.fft.fft.html). The trouble here is that this may be very long and therefore plotting a LOT of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDTAargQjSNz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "def get_fft(df):\n",
    "    N=len(df)\n",
    "    fs = len(df)/(df.index[-1]-df.index[0])\n",
    "    \n",
    "    x_plot= fftfreq(N, 1/fs)[:N//2]\n",
    "    \n",
    "    df_fft = pd.DataFrame()\n",
    "    df_phase = pd.DataFrame()\n",
    "    for name in df.columns:\n",
    "        yf = fft(df[name].values) \n",
    "        y_plot= 2.0/N * np.abs(yf[0:N//2])\n",
    "        \n",
    "        phase = np.unwrap(2 * np.angle(yf)) / 2 * 180/np.pi\n",
    "        phase = phase[0:N//2]\n",
    "        \n",
    "        df_phase = pd.concat([df_phase,\n",
    "                            pd.DataFrame({'Frequency (Hz)':x_plot[1:],\n",
    "                                          name:phase[1:]}).set_index('Frequency (Hz)')],axis=1)\n",
    "        df_fft = pd.concat([df_fft,\n",
    "                            pd.DataFrame({'Frequency (Hz)':x_plot[1:],\n",
    "                                          name:y_plot[1:]}).set_index('Frequency (Hz)')],axis=1)\n",
    "    \n",
    "    return df_fft, df_phase"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qE8BdHX1pGu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "df_fft, df_phase = get_fft(df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "sEuX5lKd0cWo",
    "outputId": "0f55d51f-529f-41c3-ff42-67adafb5217a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "fig, ax = plt.subplots() #create an empty plot\n",
    "\n",
    "df_fft.plot(ax=ax) #use the dataframe to add plot data, tell it to add to the already created axes\n",
    "\n",
    "ax.set(xlabel='Frequency (Hz)',\n",
    "       ylabel='Acceleration (g)',\n",
    "       title=filename)\n",
    "ax.grid() #turn on gridlines\n",
    "\n",
    "fig.savefig('fft.png')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "883JemLPjSk9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### FFT from PSD\n",
    "Here we can use the output of a PSD and convet it to a typical DFT. This has the benefit of allowing you to explicitely define the frequency bin width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "s1EOA2jaOnMF",
    "outputId": "0cef351f-f361-43ac-92d3-2d285a43bf73",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RD-ya2m7jUfb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def get_fft_from_psd(df,bin_width):\n",
    "  fs = len(df)/(df.index[-1]-df.index[0])\n",
    "  f, psd = signal.welch(df.to_numpy(), \n",
    "                        fs=fs, \n",
    "                        nperseg=fs/bin_width,\n",
    "                        window='hanning',\n",
    "                        axis=0,\n",
    "                        scaling = 'spectrum'\n",
    "                        )\n",
    "\n",
    "  df_psd = pd.DataFrame(psd**0.5,columns=df.columns)\n",
    "  df_psd.columns\n",
    "  df_psd['Frequency (Hz)'] = f\n",
    "  return df_psd.set_index('Frequency (Hz)')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "axwfbM7T1Gvs",
    "outputId": "ea167946-0426-49e5-8e02-228616f8c3ea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "df_fft_from_psd = get_fft_from_psd(df,.25)\n",
    "\n",
    "fig = xp.line(df_fft_from_psd)\n",
    "fig.update_layout(\n",
    "    title=\"FFT from PSD\",\n",
    "    xaxis_title=\"Frequency (Hz)\",\n",
    "    yaxis_title=\"Acceleration (g)\",\n",
    "    #xaxis_type=\"log\",\n",
    "    #yaxis_type=\"log\"\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html('fft_from_psd.html',full_html=False,include_plotlyjs='cdn')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBbcLxtXlrO6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Moving Peak Frequency\n",
    "Now we'll introduce a for loop to go through all the columns and find the moving peak frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLcuacqMnlQA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def moving_frequency(df,steps):\n",
    "  #df.index = np.linspace(df.index[0],df.index[-1],num=df.shape[0]) #resample to have uniform sampling\n",
    "  d_t = (df.index[-1]-df.index[0])/(len(df.index)-1)\n",
    "  fs = 1/d_t\n",
    "  length = df.shape[0] #full length of time series data\n",
    "  nperseg = length/5 #average 5 FFTs per segment\n",
    "  n = int(length/steps) #the number of data points per step, we will not compute\n",
    "  df_peak_freqs = pd.DataFrame(columns=df.columns)\n",
    "  for i in range(0,length-n+1,n):\n",
    "    df_sub = df.iloc[i:i+n]\n",
    "    df_psd = get_psd(df_sub, nperseg/fs)\n",
    "    time = (df_sub.index[-1]-df_sub.index[0])/2+df_sub.index[0]\n",
    "    df_peak_freqs.loc[time] = df_psd.idxmax()\n",
    "  return df_peak_freqs\n",
    "    \n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "ZDARGyY_pGc3",
    "outputId": "d516952c-3d85-4061-dc3f-b11e2e901466",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "df_peak_freqs = moving_frequency(df,40) #get rolling peak frequency for 20 different steps\n",
    "\n",
    "fig = xp.line(df_peak_freqs)\n",
    "fig.update_layout(\n",
    "    title=\"Rolling Peak Frequency\",\n",
    "    xaxis_title=\"Time (s)\",\n",
    "    yaxis_title=\"Peak Frequency (Hz)\",\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html('rolling_peak_frequency.html',full_html=False,include_plotlyjs='cdn')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FkRATc7ImdFo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Webinar-Intro-Python-Acceleration-CSV-Analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
